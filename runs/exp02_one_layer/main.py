# main.py
from pathlib import Path

import numpy as np
import torch
from torch.utils.data import DataLoader

# ==================== ì„¤ì • (í•˜ë‚˜ì˜ íŒŒì¼ì—ì„œ ëª¨ë‘ ê´€ë¦¬) ====================
CONFIG = {
    "simulation": {
        "n_samples": 50000,  # í•™ìŠµìš© ìƒ˜í”Œ ìˆ˜
        "q_points": 200,
    },
    "model": {
        "n_channels": 64,
        "depth": 4,
        "mlp_hidden": 256,
        "dropout": 0.1,
    },
    "training": {
        "batch_size": 128,
        "epochs": 5,
        "lr": 0.001,
        "weight_decay": 1e-5,
        "val_ratio": 0.2,
    },
    "paths": {
        "h5_file": Path(r"D:\data\XRR_AI\one_layer") / "xrr_1layer_small.h5",
        "stats_file": Path(r"D:\data\XRR_AI\one_layer") / "stats_1layer.pt",
        "checkpoint_dir": Path(r"D:\data\XRR_AI\one_layer") / "checkpoints",
    }
}

# ì¬í˜„ì„± ë³´ì¥
torch.manual_seed(42)
np.random.seed(42)
# =========================================================================

def main():
    print("ğŸ¯ 1-Layer XRR Regression íŒŒì´í”„ë¼ì¸ ì‹œì‘")

    # ë°ì´í„° í™•ì¸ ë° ìƒì„±
    h5_path = Path(CONFIG["paths"]["h5_file"])
    if not h5_path.exists():
        print("ë°ì´í„° íŒŒì¼ ì—†ìŒ, ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰...")
        import simulate
        simulate.generate_1layer_data()

    # ë°ì´í„°ì…‹ ìƒì„±
    from dataset import XRR1LayerDataset

    train_set = XRR1LayerDataset(h5_path, mode="train", val_ratio=CONFIG["training"]["val_ratio"])
    val_set = XRR1LayerDataset(h5_path, mode="val", val_ratio=CONFIG["training"]["val_ratio"])
    test_set = XRR1LayerDataset(h5_path, mode="test", val_ratio=CONFIG["training"]["val_ratio"])

    train_loader = DataLoader(train_set, batch_size=CONFIG["training"]["batch_size"],
                             shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_set, batch_size=CONFIG["training"]["batch_size"],
                           shuffle=False, num_workers=4)
    test_loader = DataLoader(test_set, batch_size=CONFIG["training"]["batch_size"],
                            shuffle=False, num_workers=2)

    print(f"ğŸ“Š ë°ì´í„°ì…‹: Train={len(train_set)}, Val={len(val_set)}, Test={len(test_set)}")

    # ëª¨ë¸ ìƒì„±
    from model import XRR1DRegressor

    q_len = train_set.q_values.shape[0]
    model = XRR1DRegressor(
        q_len=q_len,
        n_channels=CONFIG["model"]["n_channels"],
        depth=CONFIG["model"]["depth"],
        mlp_hidden=CONFIG["model"]["mlp_hidden"],
        dropout=CONFIG["model"]["dropout"],
    )

    print(f"ğŸ¤– ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}")

    # í•™ìŠµ
    from train import Trainer

    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        lr=CONFIG["training"]["lr"],
        weight_decay=CONFIG["training"]["weight_decay"],
        checkpoint_dir=CONFIG["paths"]["checkpoint_dir"],
    )

    trainer.train(CONFIG["training"]["epochs"])

    # ìµœì¢… í‰ê°€
    print("\n" + "="*50)
    print("ğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€")
    print("="*50)

    from evaluate import load_model_and_evaluate

    checkpoint_path = Path(CONFIG["paths"]["checkpoint_dir"]) / "best.pt"
    stats_path = Path(CONFIG["paths"]["stats_file"])

    load_model_and_evaluate(checkpoint_path, h5_path, stats_path)

if __name__ == "__main__":
    main()
